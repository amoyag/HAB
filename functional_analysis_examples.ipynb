{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9YwmD1TXN5RcBr/s2HceL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amoyag/HAB_24-25/blob/main/functional_analysis_examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython"
      ],
      "metadata": {
        "id": "8lcOlBStPMqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import Entrez\n",
        "import time\n",
        "\n",
        "# Use Entrez to search for genes and fetch their functional annotations\n",
        "Entrez.email = \"your_email@example.com\"\n",
        "\n",
        "# Define the list of glycolysis genes\n",
        "gene_symbols = [\"GAPDH\", \"PKM\", \"ALDOA\", \"HK1\", \"PFKM\", \"LDHA\"]\n",
        "\n",
        "# Iterate over each gene to fetch annotations\n",
        "for gene in gene_symbols:\n",
        "    try:\n",
        "        # Search for the gene in Entrez\n",
        "        handle = Entrez.esearch(db=\"gene\", term=f\"{gene}[Gene] AND Homo sapiens[Organism]\")\n",
        "        record = Entrez.read(handle)\n",
        "        handle.close()\n",
        "\n",
        "        if record['IdList']:\n",
        "            gene_id = record['IdList'][0]\n",
        "\n",
        "            # Fetch the gene summary to get functional annotations\n",
        "            handle = Entrez.efetch(db=\"gene\", id=gene_id, rettype=\"gb\", retmode=\"text\")\n",
        "            gene_record = handle.read()\n",
        "            handle.close()\n",
        "\n",
        "            # Print the fetched annotation\n",
        "            print(f\"Annotations for {gene}:\\n\")\n",
        "            print(gene_record)\n",
        "            print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "        else:\n",
        "            print(f\"No record found for gene: {gene}\")\n",
        "\n",
        "        # Pause to avoid overwhelming the Entrez servers\n",
        "        time.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while fetching annotations for {gene}: {e}\")\n"
      ],
      "metadata": {
        "id": "dUbzTsidPUo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install goatools\n",
        "!pip install requests\n",
        "!pip install mygene"
      ],
      "metadata": {
        "collapsed": true,
        "id": "e1o90EeYQ6mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from goatools import obo_parser\n",
        "from goatools.go_enrichment import GOEnrichmentStudy\n",
        "from goatools.associations import read_gaf\n",
        "import random\n",
        "import requests\n",
        "import gzip\n",
        "import shutil\n",
        "import os\n",
        "import mygene\n",
        "\n",
        "### Download stuff\n",
        "\n",
        "## Get the GO ontology obo file\n",
        "# URL of the go-basic.obo file\n",
        "obo_url = \"http://current.geneontology.org/ontology/go-basic.obo\"\n",
        "obo_file_path = \"go-basic.obo\"\n",
        "\n",
        "# Download only if the file does not already exist\n",
        "if not os.path.exists(obo_file_path):\n",
        "    try:\n",
        "        response = requests.get(obo_url)\n",
        "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "        with open(obo_file_path, 'wb') as file:\n",
        "            file.write(response.content)\n",
        "        print(f\"Successfully downloaded 'go-basic.obo' to {obo_file_path}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"An error occurred while downloading the file: {e}\")\n",
        "else:\n",
        "    print(f\"'{obo_file_path}' already exists. Skipping download.\")\n",
        "\n",
        "## Download the GAF file\n",
        "# URL of the goa_human.gaf file\n",
        "gaf_url = \"http://current.geneontology.org/annotations/goa_human.gaf.gz\"\n",
        "compressed_gaf_file_path = \"goa_human.gaf.gz\"\n",
        "extracted_gaf_file_path = \"goa_human.gaf\"\n",
        "\n",
        "# Download and extract only if the file does not already exist\n",
        "if not os.path.exists(extracted_gaf_file_path):\n",
        "    try:\n",
        "        response = requests.get(gaf_url)\n",
        "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "        with open(compressed_gaf_file_path, 'wb') as file:\n",
        "            file.write(response.content)\n",
        "        print(f\"Successfully downloaded 'goa_human.gaf.gz' to {compressed_gaf_file_path}\")\n",
        "\n",
        "        # Extract the .gz file\n",
        "        with gzip.open(compressed_gaf_file_path, 'rb') as f_in:\n",
        "            with open(extracted_gaf_file_path, 'wb') as f_out:\n",
        "                shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "        print(f\"Successfully extracted '{extracted_gaf_file_path}'\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"An error occurred while downloading the file: {e}\")\n",
        "else:\n",
        "    print(f\"'{extracted_gaf_file_path}' already exists. Skipping download.\")\n",
        "\n",
        "### Convert genes ID to UniProt ID\n",
        "# Initialize MyGene client\n",
        "mg = mygene.MyGeneInfo()\n",
        "\n",
        "# Convert gene symbols to UniProt IDs\n",
        "gene_symbols = [\"GAPDH\", \"PKM\", \"ALDOA\", \"HK1\", \"PFKM\", \"LDHA\"]\n",
        "query_result = mg.querymany(gene_symbols, scopes='symbol', fields='uniprot', species='human')\n",
        "\n",
        "# Extract UniProt IDs for the study genes\n",
        "study_gene_uniprot_ids = []\n",
        "for gene in query_result:\n",
        "    uniprot_id = gene.get('uniprot', {}).get('Swiss-Prot')\n",
        "    if uniprot_id:\n",
        "        study_gene_uniprot_ids.append(uniprot_id)\n",
        "\n",
        "# Print the UniProt IDs for each gene\n",
        "print(\"Converted UniProt IDs for the study genes:\")\n",
        "for gene_symbol, uniprot_id in zip(gene_symbols, study_gene_uniprot_ids):\n",
        "    print(f\"Gene Symbol: {gene_symbol}, UniProt ID: {uniprot_id}\")\n",
        "\n",
        "### Set the background list and perform ORA\n",
        "\n",
        "# Extract all genes from the GAF file\n",
        "all_genes = set()\n",
        "\n",
        "try:\n",
        "    with open(extracted_gaf_file_path, 'r') as gaf_file:\n",
        "        for line in gaf_file:\n",
        "            # Skip comments\n",
        "            if line.startswith(\"!\"):\n",
        "                continue\n",
        "\n",
        "            # Split the GAF line by tab\n",
        "            columns = line.strip().split(\"\\t\")\n",
        "\n",
        "            # Column 2 contains the systematic identifier (e.g., UniProt ID)\n",
        "            gene_identifier = columns[1]\n",
        "\n",
        "            # Add the gene identifier to the set of all genes\n",
        "            all_genes.add(gene_identifier)\n",
        "\n",
        "    print(f\"Successfully extracted {len(all_genes)} gene identifiers from the GAF file.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"File '{extracted_gaf_file_path}' not found. Please make sure it is available.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading the GAF file: {e}\")\n",
        "\n",
        "# Convert to list for sampling\n",
        "all_genes_list = list(all_genes)\n",
        "\n",
        "# Randomly sample 1000 genes from the full list\n",
        "random.seed(42)  # Set seed for reproducibility\n",
        "background_gene_list = random.sample(all_genes_list, 1000)\n",
        "\n",
        "# Ensure that all study genes are included in the background list\n",
        "for gene in study_gene_uniprot_ids:\n",
        "    if gene not in background_gene_list:\n",
        "        background_gene_list.append(gene)\n",
        "\n",
        "# Perform GO enrichment analysis with GOATOOLS using the updated study list\n",
        "\n",
        "# Load the GO ontology\n",
        "go = obo_parser.GODag(obo_file_path)\n",
        "\n",
        "# Load gene-to-GO associations in GAF format\n",
        "gene2go = read_gaf(extracted_gaf_file_path)\n",
        "\n",
        "# Perform GO enrichment analysis\n",
        "go_enrich = GOEnrichmentStudy(\n",
        "    background_gene_list,  # Updated background with genes\n",
        "    gene2go,               # Gene to GO term associations\n",
        "    go,                    # Gene Ontology DAG\n",
        "    propagate_counts=False,\n",
        "    alpha=0.05,            # Significance cutoff\n",
        "    methods=['fdr_bh']     # Multiple testing correction\n",
        ")\n",
        "\n",
        "# Run study with UniProt IDs from the study set\n",
        "enriched_results = go_enrich.run_study(study_gene_uniprot_ids)\n",
        "\n",
        "# Print the enriched GO terms\n",
        "for res in enriched_results:\n",
        "    if res.p_fdr_bh < 0.05:\n",
        "        print(f\"GO ID: {res.GO}, Description: {res.name}, P-value: {res.p_fdr_bh}\")"
      ],
      "metadata": {
        "id": "x-WZVrY5hBCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gseapy\n",
        "!pip install pandas"
      ],
      "metadata": {
        "id": "-9pIwxA3jEsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gseapy as gp\n",
        "import pandas as pd\n",
        "\n",
        "# Define the list of glycolysis genes and convert them to uppercase\n",
        "glycolysis_genes = [\"GAPDH\", \"PKM\", \"ALDOA\", \"HK1\", \"PFKM\", \"LDHA\"]\n",
        "glycolysis_genes_upper = [gene.upper() for gene in glycolysis_genes]\n",
        "\n",
        "# Create a DataFrame to mimic expression data for GSEA analysis\n",
        "# In practice, this would come from experimental results (e.g., RNA-seq)\n",
        "# Here we create mock expression data for illustration purposes\n",
        "mock_expression_data = {\n",
        "    'Gene': glycolysis_genes_upper,\n",
        "    'Expression': [2.3, 1.8, 2.1, 1.9, 2.5, 2.0]  # Random fold change values for example purposes\n",
        "}\n",
        "\n",
        "# Convert the mock data to a DataFrame\n",
        "expression_df = pd.DataFrame(mock_expression_data)\n",
        "expression_df.set_index('Gene', inplace=True)\n",
        "\n",
        "# Print the mock expression data to see what it looks like\n",
        "print(\"Mock Expression Data:\")\n",
        "print(expression_df)\n",
        "\n",
        "# Save expression data to a CSV file to use for GSEA\n",
        "expression_df.to_csv('expression_data.csv')\n",
        "\n",
        "# Run GSEA Preranked analysis with gseapy\n",
        "# Use a predefined pathway gene set like KEGG\n",
        "try:\n",
        "    gsea_results = gp.prerank(\n",
        "        rnk='expression_data.csv',  # Ranked gene list, usually the output of a differential analysis\n",
        "        gene_sets='KEGG_2016',      # Gene set database; using KEGG pathways for example\n",
        "        outdir='gsea_output',       # Output directory\n",
        "        permutation_num=100,        # Number of permutations for significance testing\n",
        "        min_size=3,                 # Minimum size of the gene set to include\n",
        "        max_size=5000,              # Maximum size of the gene set to include\n",
        "    )\n",
        "\n",
        "    # Print top 5 results\n",
        "    print(\"\\nTop 5 Enriched Pathways:\")\n",
        "    print(gsea_results.res2d.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during GSEA analysis: {e}\")\n"
      ],
      "metadata": {
        "id": "2TMsR1AkjDJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Define the list of glycolysis genes and convert them to uppercase\n",
        "glycolysis_genes = [\"GAPDH\", \"PKM\", \"ALDOA\", \"HK1\", \"PFKM\", \"LDHA\"]\n",
        "glycolysis_genes_upper = [gene.upper() for gene in glycolysis_genes]\n",
        "\n",
        "# Enrichr API URLs\n",
        "add_list_url = \"https://maayanlab.cloud/Enrichr/addList\"\n",
        "enrich_url = \"https://maayanlab.cloud/Enrichr/enrich\"\n",
        "\n",
        "# Add genes to Enrichr\n",
        "gene_str = \"\\n\".join(glycolysis_genes_upper)  # Enrichr requires newline-separated gene symbols\n",
        "payload = {\n",
        "    'list': (None, gene_str),\n",
        "    'description': (None, 'Glycolysis Genes List')\n",
        "}\n",
        "\n",
        "response = requests.post(add_list_url, files=payload)\n",
        "if response.status_code == 200:\n",
        "    result = response.json()\n",
        "    user_list_id = result['userListId']\n",
        "    print(f\"Successfully added genes to Enrichr. User List ID: {user_list_id}\")\n",
        "else:\n",
        "    print(f\"Error adding genes to Enrichr: {response.status_code}\")\n",
        "    exit()\n",
        "\n",
        "# Perform enrichment analysis\n",
        "gene_set_library = 'KEGG_2019_Human'  # Example: KEGG pathways\n",
        "params = {\n",
        "    'userListId': user_list_id,\n",
        "    'backgroundType': gene_set_library\n",
        "}\n",
        "\n",
        "response = requests.get(enrich_url, params=params)\n",
        "if response.status_code == 200:\n",
        "    enrichment_results = response.json()\n",
        "    if gene_set_library in enrichment_results:\n",
        "        print(\"\\nEnrichment Analysis Results (Top Results):\")\n",
        "        for result in enrichment_results[gene_set_library][:5]:  # Display top 5 results\n",
        "            # result is a list, so we access items by index\n",
        "            term_name = result[1]  # Term name\n",
        "            pvalue = result[2]     # P-value\n",
        "            combined_score = result[4]  # Combined score\n",
        "\n",
        "            print(f\"Term: {term_name}, P-value: {pvalue}, Combined Score: {combined_score}\")\n",
        "    else:\n",
        "        print(\"The expected gene set library was not found in the enrichment results.\")\n",
        "else:\n",
        "    print(f\"Error retrieving enrichment results: {response.status_code}\")\n"
      ],
      "metadata": {
        "id": "RgeN8XYhnqsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# STRINGdb API URL and method details\n",
        "string_api_url = \"https://version-11-5.string-db.org/api\"\n",
        "output_format = \"json\"\n",
        "method = \"enrichment\"\n",
        "\n",
        "# Construct the request URL\n",
        "request_url = \"/\".join([string_api_url, output_format, method])\n",
        "\n",
        "# Glycolysis genes to use for functional enrichment analysis\n",
        "glycolysis_genes = [\"GAPDH\", \"PKM\", \"ALDOA\", \"HK1\", \"PFKM\", \"LDHA\"]\n",
        "\n",
        "# Define the parameters for the request\n",
        "params = {\n",
        "    \"identifiers\": \"%0d\".join(glycolysis_genes),  # Protein list formatted with %0d (newline separator)\n",
        "    \"species\": 9606,  # Species NCBI identifier for Homo sapiens (human)\n",
        "    \"caller_identity\": \"test_HAB\"  # Replace with your own identifier or email address\n",
        "}\n",
        "\n",
        "# Make the POST request to STRINGdb API\n",
        "response = requests.post(request_url, data=params)\n",
        "\n",
        "# Parse the JSON response\n",
        "data = json.loads(response.text)\n",
        "\n",
        "# Print the significant GO Biological Process (Process) annotations\n",
        "print(\"Functional Enrichment Analysis Results (GO Biological Process Only, FDR < 0.01):\")\n",
        "for row in data:\n",
        "    term = row[\"term\"]\n",
        "    preferred_names = \",\".join(row[\"preferredNames\"])\n",
        "    fdr = float(row[\"fdr\"])\n",
        "    description = row[\"description\"]\n",
        "    category = row[\"category\"]\n",
        "\n",
        "    # Filter results to only include GO Biological Processes with FDR < 0.01\n",
        "    if category == \"Process\" and fdr < 0.01:\n",
        "        print(\"\\t\".join([term, preferred_names, str(fdr), category, description]))\n"
      ],
      "metadata": {
        "id": "C-XwSa0Po8KS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}